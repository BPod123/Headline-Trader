{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import tqdm\n",
    "from BOW_data_format import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "prepared = prepare_data()\n",
    "title_data = prepared['title_data']\n",
    "train_data = prepared['train']\n",
    "validation_data = prepared['validation']\n",
    "test_data = prepared['test']\n",
    "vocab = prepared['vocab']\n",
    "PAD_ID = prepared['PAD_ID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "titles = nn.utils.rnn.pad_sequence([torch.LongTensor(title_data[i]) if i in title_data else torch.LongTensor([PAD_ID]) for i in range(max(title_data) + 1)], batch_first=True).contiguous()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Data Loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def bag_of_words_collate(batch):\n",
    "    batch_arr = np.array(batch).T\n",
    "    data = titles[batch_arr[0]]\n",
    "    labels = torch.FloatTensor(batch_arr[1]).to(device)\n",
    "    return data.to(device), labels.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=RandomSampler(train_data), collate_fn=bag_of_words_collate)\n",
    "validation_iter = DataLoader(validation_data, sampler=RandomSampler(validation_data), batch_size=BATCH_SIZE, collate_fn=bag_of_words_collate, drop_last=False)\n",
    "test_iter = DataLoader(test_data, sampler=RandomSampler(test_data), batch_size=BATCH_SIZE, collate_fn=bag_of_words_collate, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, dropout=0.4):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(embedding_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.logit(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    def logit(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.dropout(out.mean(1))\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def eval_model(model, data_iter):\n",
    "    model.eval()\n",
    "    predictions, all_labels= [], []\n",
    "    for (data, labels) in data_iter:\n",
    "        out = model(data)\n",
    "        predictions.append(out.unsqueeze(0))\n",
    "        all_labels.append(labels.unsqueeze(0))\n",
    "    pred = torch.cat(predictions, axis=1).squeeze()\n",
    "    pred = (pred - pred.mean() + 0.5).round().to('cpu')\n",
    "\n",
    "    true = torch.cat(all_labels, axis=1).squeeze().to('cpu')\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1_scores = []\n",
    "    for selected_class in range(2):\n",
    "        tp = ((pred == selected_class) & (true == selected_class)).sum()\n",
    "        fp = ((pred == selected_class) & (true != selected_class)).sum()\n",
    "        fn = ((pred != selected_class) & (true == selected_class)).sum()\n",
    "        recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "        precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return pred, true, recalls, precisions, f1_scores\n",
    "\n",
    "def eval_on_test_set(model):\n",
    "    _, _, recalls, precisions, f1_scores = eval_model(model, test_iter)\n",
    "    print(f\"\"\"Run on Test Data:\n",
    "    Down: Recall: {recalls[0]}\\tPrecision: {precisions[0]}\\tF1: {f1_scores[0]}\n",
    "    Up: Recall: {recalls[1]}\\tPrecision: {precisions[1]}\\tF1: {f1_scores[1]}\n",
    "    AVERAGE: Recall: {sum(recalls) / 2}\\tPrecision: {sum(precisions) / 2}\\tF1: {sum(f1_scores) / 2}\"\"\")\n",
    "\n",
    "def eval_summary(epoch):\n",
    "        _, _, recalls, precisions, f1_scores = eval_model(model, validation_iter)\n",
    "        print(f\"\"\"Epoch {epoch} Validation:\n",
    "Down: Recall: {recalls[0]}\\tPrecision: {precisions[0]}\\tF1: {f1_scores[0]}\n",
    "Up: Recall: {recalls[1]}\\tPrecision: {precisions[1]}\\tF1: {f1_scores[1]}\n",
    "AVERAGE: Recall: {sum(recalls) / 2}\\tPrecision: {sum(precisions) / 2}\\tF1: {sum(f1_scores) / 2}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def train_model(model, data_iter, epochs, optimizer, scheduler, loss_func):\n",
    "    epoch_average_losses = []\n",
    "    with tqdm.notebook.trange(epochs, desc='training', unit='epoch') as epoch_iter:\n",
    "        for epoch in epoch_iter:\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_samples = 0\n",
    "            with tqdm.notebook.tqdm(data_iter, desc=f\"epoch {epoch + 1}\", unit='batch', total=len(data_iter)) as batch_iter:\n",
    "                for i, (data, labels) in enumerate(batch_iter, start=1):\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model.logit(data)\n",
    "                    loss = loss_func(output.squeeze(), labels.squeeze())\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_samples += data.shape[0]\n",
    "                    if i == len(batch_iter):\n",
    "                        _, _, recalls, precisions, f1_scores = eval_model(model, validation_iter)\n",
    "                        batch_iter.set_postfix(mean_epoch_loss=epoch_loss / i, Val_F1_0=f1_scores[0].item(), Val_F1_1=f1_scores[1].item(), Val_Prec_0=precisions[0].item(), Val_Prec_1=precisions[1].item(), Val_Recall_0=recalls[0].item(), Val_Recall_1=recalls[1].item())\n",
    "                    else:\n",
    "                        batch_iter.set_postfix(mean_epoch_loss=epoch_loss / i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / epoch_samples\n",
    "            scheduler.step(avg_epoch_loss)\n",
    "            epoch_average_losses.append(avg_epoch_loss)\n",
    "\n",
    "    return epoch_average_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "EPOCHS = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre Training Stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on Test Data:\n",
      "    Down: Recall: 0.5\tPrecision: 0.4333333373069763\tF1: 0.4642857313156128\n",
      "    Up: Recall: 0.3199999928474426\tPrecision: 0.380952388048172\tF1: 0.3478260636329651\n",
      "    AVERAGE: Recall: 0.4099999964237213\tPrecision: 0.40714287757873535\tF1: 0.40605589747428894\n",
      "\n",
      "\n",
      "Epoch 0 Validation:\n",
      "Down: Recall: 0.4637681245803833\tPrecision: 0.761904776096344\tF1: 0.5765765905380249\n",
      "Up: Recall: 0.6296296119689941\tPrecision: 0.31481480598449707\tF1: 0.4197530746459961\n",
      "AVERAGE: Recall: 0.5466988682746887\tPrecision: 0.5383597612380981\tF1: 0.4981648325920105\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = BagOfWords(len(vocab), 1200).to(device)\n",
    "eval_on_test_set(model)\n",
    "print('\\n')\n",
    "eval_summary(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "training:   0%|          | 0/50 [00:00<?, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e17f598c4e874081ac6f760e679024c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 1:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fea33790f2648cf98dadf9e1896f1a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 2:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c83c64ec4b7549c0a0d2e46408095da5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 3:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2323a66da65549ddb26ad62733fbed90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 4:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc1805039dff4ffab9eea34766b74c95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 5:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ab7cda12d2a4fb29380cf7df20fccd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 6:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c0fc19603cd480e97e30d8883bf06ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 7:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dab2317219d4a98bd6fba04c4e20e5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 8:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d60cb1b4d7741cc9b2f4cb8f369b2dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 9:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8a914d1d834146bfea62d95f6428f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 10:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "545d33f47abb42c7b2bff88fb1bb712d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 11:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de832128be5345c3a3d7ccd51f5fd718"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 12:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b23c97db9e743dd979ac9d5c60e642e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 13:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a71b4e0978444b52892a06d71d466abf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 14:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f9b90d1ca40402fa4de9051a8b71488"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 15:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d9d69e82be24661a0a2c86d2b4efda5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 16:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44a8d0891f6647af9b3ded8aa41a59e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 17:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59377d7d8e2f4b359f2f7438b66df65c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 18:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad453de8eaa54bd4a6e336ef19a6c441"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 19:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8a8c74c91e54fac856cef79526154d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 20:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5aefcb40105437e9c15dcb4a231056d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 21:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f84c642781a480a9c1d875ae40f775a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 22:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ccd002a0f2c4534b64f66ed21ea1617"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 23:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fbcc34c84154c7c8d101681ba19690e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 24:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1717b9310a4a4876a15738cb8c60182a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 25:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25d7430bcd9a412782be3f360c9206b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 26:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1f53b62dfa74402848ab7cc1f1a527e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 27:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93dbdcb465254f5c84afb32019900b15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 28:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8a3a71161774f0eafecaafcb04cac56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 29:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b1235605c10414297314737da2b2a5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 30:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc4240fc6ebb4f06b056866ee2e25a9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 31:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "983ff9c6954d4eb9a09996c4c1e52229"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 32:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5f3739601134aa3ab6bc122d4016df4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 33:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ade494c2f01b4db3b4a62a26338ff0b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 34:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c7f86cf11894bd1934f9b353850aa43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 35:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a523f3ae7cf44ecca7ff7bda26f229f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 36:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8e2defee7944cfd999b3e3220c560d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 37:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d382e266321a4faba07350c7eb42aee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 38:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb420af6a334437cb239a36557ff363c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 39:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da9f72688e7b435e9d3db7a83b4cf6c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 40:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "708500fa05ed4703a83bd1dca691efb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 41:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2b9d3dd59fd41b0b52a07ff7bc0a4d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 42:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4f367ee906a49cd8fa0e2f8263deb38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 43:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b473ba93ceed4523a29c771b7165c30a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 44:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eeae8a97f384cf9a76ebe75f9340362"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 45:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d20a2cad85c44dfc9c2b86169609aafd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 46:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21491acfcba74124803acb5de1d39e08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 47:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c156c275d0949d9917f51dd2127e8c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 48:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18f58463262c44a3b8c9464de28dc385"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 49:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a67eeef579524ed28bb713e727a7f94a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 50:   0%|          | 0/99 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3f8724fd9b040e58bac16fea3f7da87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=3, threshold=0.01)\n",
    "history = train_model(model, train_iter, EPOCHS, optimizer, scheduler, loss_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('../Saved_Models'):\n",
    "    os.mkdir('../Saved_Models')\n",
    "torch.save(model, '../Saved_Models/bag_of_words.pt')\n",
    "bag = torch.load('../Saved_Models/bag_of_words.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Post Training Stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Validation:\n",
      "Down: Recall: 0.5507246255874634\tPrecision: 0.7916666865348816\tF1: 0.6495726704597473\n",
      "Up: Recall: 0.6296296119689941\tPrecision: 0.3541666567325592\tF1: 0.4533333480358124\n",
      "AVERAGE: Recall: 0.5901771187782288\tPrecision: 0.5729166865348816\tF1: 0.5514529943466187\n",
      "\n",
      "\n",
      "Run on Test Data:\n",
      "    Down: Recall: 0.5384615659713745\tPrecision: 0.5833333134651184\tF1: 0.559999942779541\n",
      "    Up: Recall: 0.6000000238418579\tPrecision: 0.5555555820465088\tF1: 0.576923131942749\n",
      "    AVERAGE: Recall: 0.5692307949066162\tPrecision: 0.5694444179534912\tF1: 0.568461537361145\n"
     ]
    }
   ],
   "source": [
    "eval_summary(EPOCHS)\n",
    "print('\\n')\n",
    "eval_on_test_set(bag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write results to CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def run_on_data(model, data_iter):\n",
    "    model.eval()\n",
    "    predictions, all_labels= [], []\n",
    "    for (data, labels) in data_iter:\n",
    "        out = model(data)\n",
    "        predictions.append(out.unsqueeze(0))\n",
    "        all_labels.append(labels.unsqueeze(0))\n",
    "    pred = torch.cat(predictions, axis=1).squeeze()\n",
    "    pred -= pred.mean()\n",
    "    pred += 0.5\n",
    "    true = torch.cat(all_labels, axis=1).squeeze()\n",
    "    return pred, true\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "train_pred, train_labels = run_on_data(model, train_iter)\n",
    "valid_pred, valid_labels = run_on_data(model, validation_iter)\n",
    "test_pred, test_labels = run_on_data(model, test_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_results = pd.DataFrame({\"Labels\": train_labels.to('cpu'), \"Predictions\": train_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": #train_data['Date']})\n",
    "valid_results = pd.DataFrame({\"Labels\": valid_labels.to('cpu'), \"Predictions\": valid_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": validation_data['Date']})\n",
    "test_results = pd.DataFrame({\"Labels\": test_labels.to('cpu'), \"Predictions\": test_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": test_data['Date']})\n",
    "\n",
    "train_results.to_csv('../Results/train/BOW.csv', index=False)\n",
    "valid_results.to_csv('../Results/validation/BOW.csv', index=False)\n",
    "test_results.to_csv('../Results/test/BOW.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}