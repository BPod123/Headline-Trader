{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import tqdm\n",
    "from BOW_data_format import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "prepared = prepare_data()\n",
    "title_data = prepared['title_data']\n",
    "train_data = prepared['train']\n",
    "validation_data = prepared['validation']\n",
    "test_data = prepared['test']\n",
    "vocab = prepared['vocab']\n",
    "PAD_ID = prepared['PAD_ID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "titles = nn.utils.rnn.pad_sequence([torch.LongTensor(title_data[i]) if i in title_data else torch.LongTensor([PAD_ID]) for i in range(max(title_data) + 1)], batch_first=True).contiguous()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Data Loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def bag_of_words_collate(batch):\n",
    "    batch_arr = np.array(batch).T\n",
    "    data = titles[batch_arr[0]]\n",
    "    labels = torch.FloatTensor(batch_arr[1]).to(device)\n",
    "    return data.to(device), labels.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=RandomSampler(train_data), collate_fn=bag_of_words_collate)\n",
    "validation_iter = DataLoader(validation_data, sampler=RandomSampler(validation_data), batch_size=BATCH_SIZE, collate_fn=bag_of_words_collate, drop_last=False)\n",
    "test_iter = DataLoader(test_data, sampler=RandomSampler(test_data), batch_size=BATCH_SIZE, collate_fn=bag_of_words_collate, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, dropout=0.4):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(embedding_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.logit(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    def logit(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.dropout(out.mean(1))\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def eval_model(model, data_iter):\n",
    "    model.eval()\n",
    "    predictions, all_labels= [], []\n",
    "    for (data, labels) in data_iter:\n",
    "        out = model(data)\n",
    "        predictions.append(out.unsqueeze(0))\n",
    "        all_labels.append(labels.unsqueeze(0))\n",
    "    pred = torch.cat(predictions, axis=1).squeeze()\n",
    "    pred = (pred - pred.mean() + 0.5).round().to('cpu')\n",
    "\n",
    "    true = torch.cat(all_labels, axis=1).squeeze().to('cpu')\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1_scores = []\n",
    "    for selected_class in range(2):\n",
    "        tp = ((pred == selected_class) & (true == selected_class)).sum()\n",
    "        fp = ((pred == selected_class) & (true != selected_class)).sum()\n",
    "        fn = ((pred != selected_class) & (true == selected_class)).sum()\n",
    "        recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "        precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "        recalls.append(recall if recall == 0 else recall.item())\n",
    "        precisions.append(precision if precision == 0 else precision.item())\n",
    "        f1_scores.append(f1 if f1 == 0 else f1.item())\n",
    "\n",
    "    return pred, true, recalls, precisions, f1_scores\n",
    "\n",
    "def eval_on_test_set(model):\n",
    "    _, _, recalls, precisions, f1_scores = eval_model(model, test_iter)\n",
    "    print(f\"\"\"Run on Test Data:\n",
    "    Down: Recall: {recalls[0]}\\tPrecision: {precisions[0]}\\tF1: {f1_scores[0]}\n",
    "    Up: Recall: {recalls[1]}\\tPrecision: {precisions[1]}\\tF1: {f1_scores[1]}\n",
    "    AVERAGE: Recall: {sum(recalls) / 2}\\tPrecision: {sum(precisions) / 2}\\tF1: {sum(f1_scores) / 2}\"\"\")\n",
    "\n",
    "def eval_summary(epoch):\n",
    "        _, _, recalls, precisions, f1_scores = eval_model(model, validation_iter)\n",
    "        print(f\"\"\"Epoch {epoch} Validation:\n",
    "Down: Recall: {recalls[0]}\\tPrecision: {precisions[0]}\\tF1: {f1_scores[0]}\n",
    "Up: Recall: {recalls[1]}\\tPrecision: {precisions[1]}\\tF1: {f1_scores[1]}\n",
    "AVERAGE: Recall: {sum(recalls) / 2}\\tPrecision: {sum(precisions) / 2}\\tF1: {sum(f1_scores) / 2}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def train_model(model, data_iter, epochs, optimizer, scheduler, loss_func):\n",
    "    epoch_average_losses = []\n",
    "    with tqdm.notebook.trange(epochs, desc='training', unit='epoch') as epoch_iter:\n",
    "        for epoch in epoch_iter:\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_samples = 0\n",
    "            with tqdm.notebook.tqdm(data_iter, desc=f\"epoch {epoch + 1}\", unit='batch', total=len(data_iter)) as batch_iter:\n",
    "                for i, (data, labels) in enumerate(batch_iter, start=1):\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model.logit(data)\n",
    "                    loss = loss_func(output.squeeze(), labels.squeeze())\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_samples += data.shape[0]\n",
    "                    if i == len(batch_iter):\n",
    "                        _, _, recalls, precisions, f1_scores = eval_model(model, validation_iter)\n",
    "                        batch_iter.set_postfix(mean_epoch_loss=epoch_loss / i, Val_F1_0=f1_scores[0], Val_F1_1=f1_scores[1], Val_Prec_0=precisions[0], Val_Prec_1=precisions[1], Val_Recall_0=recalls[0], Val_Recall_1=recalls[1])\n",
    "                    else:\n",
    "                        batch_iter.set_postfix(mean_epoch_loss=epoch_loss / i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / epoch_samples\n",
    "            scheduler.step(avg_epoch_loss)\n",
    "            epoch_average_losses.append(avg_epoch_loss)\n",
    "\n",
    "    return epoch_average_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre Training Stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on Test Data:\n",
      "    Down: Recall: 0.6730769276618958\tPrecision: 0.7291666865348816\tF1: 0.699999988079071\n",
      "    Up: Recall: 0.7400000095367432\tPrecision: 0.6851851940155029\tF1: 0.7115384340286255\n",
      "    AVERAGE: Recall: 0.7065384685993195\tPrecision: 0.7071759402751923\tF1: 0.7057692110538483\n",
      "\n",
      "\n",
      "Epoch 0 Validation:\n",
      "Down: Recall: 0.36231884360313416\tPrecision: 0.5952380895614624\tF1: 0.45045045018196106\n",
      "Up: Recall: 0.37037035822868347\tPrecision: 0.18518517911434174\tF1: 0.2469135820865631\n",
      "AVERAGE: Recall: 0.3663446009159088\tPrecision: 0.39021163433790207\tF1: 0.3486820161342621\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = BagOfWords(len(vocab), 300, 0.1).to(device)\n",
    "eval_on_test_set(model)\n",
    "print('\\n')\n",
    "eval_summary(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "training:   0%|          | 0/10 [00:00<?, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52f6b2f287a741e1a8f6edec96dca92c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 1:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a82823782f144694b2b05d621048ff6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 2:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea47a4bba5a04ae1a55acb109c084a28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 3:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bd6db59f3dd4d73b51faa955d70b320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 4:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0273a75a012e47ffa532607b80285a73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 5:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4f9d26a6dc6499191d3d719bb1395c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 6:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ce1b6afb2d0421699b308c673eda3f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 7:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41d50c00fbd7441ab18bd46489b7c1fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 8:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45651607659d4eaea41396b0170e7722"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 9:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08137ba001dc42618de912015eb1197c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "epoch 10:   0%|          | 0/198 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9a5bc57e920416897c5bdc06f123a4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=3, threshold=0.01)\n",
    "history = train_model(model, train_iter, EPOCHS, optimizer, scheduler, loss_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('../Saved_Models'):\n",
    "    os.mkdir('../Saved_Models')\n",
    "torch.save(model, '../Saved_Models/bag_of_words.pt')\n",
    "bag = torch.load('../Saved_Models/bag_of_words.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Post Training Stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation:\n",
      "Down: Recall: 0.36231884360313416\tPrecision: 0.5952380895614624\tF1: 0.45045045018196106\n",
      "Up: Recall: 0.37037035822868347\tPrecision: 0.18518517911434174\tF1: 0.2469135820865631\n",
      "AVERAGE: Recall: 0.3663446009159088\tPrecision: 0.39021163433790207\tF1: 0.3486820161342621\n",
      "\n",
      "\n",
      "Run on Test Data:\n",
      "    Down: Recall: 0.6346153616905212\tPrecision: 0.6111111044883728\tF1: 0.6226415038108826\n",
      "    Up: Recall: 0.5799999833106995\tPrecision: 0.6041666865348816\tF1: 0.5918367505073547\n",
      "    AVERAGE: Recall: 0.6073076725006104\tPrecision: 0.6076388955116272\tF1: 0.6072391271591187\n"
     ]
    }
   ],
   "source": [
    "eval_summary(EPOCHS)\n",
    "print('\\n')\n",
    "eval_on_test_set(bag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write results to CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def run_on_data(model, data_iter):\n",
    "    model.eval()\n",
    "    predictions, all_labels= [], []\n",
    "    for (data, labels) in data_iter:\n",
    "        out = model(data)\n",
    "        predictions.append(out.unsqueeze(0))\n",
    "        all_labels.append(labels.unsqueeze(0))\n",
    "    pred = torch.cat(predictions, axis=1).squeeze()\n",
    "    pred -= pred.mean()\n",
    "    pred += 0.5\n",
    "    true = torch.cat(all_labels, axis=1).squeeze()\n",
    "    return pred, true\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "train_pred, train_labels = run_on_data(model, train_iter)\n",
    "valid_pred, valid_labels = run_on_data(model, validation_iter)\n",
    "test_pred, test_labels = run_on_data(model, test_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_results = pd.DataFrame({\"Labels\": train_labels.to('cpu'), \"Predictions\": train_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": #train_data['Date']})\n",
    "valid_results = pd.DataFrame({\"Labels\": valid_labels.to('cpu'), \"Predictions\": valid_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": validation_data['Date']})\n",
    "test_results = pd.DataFrame({\"Labels\": test_labels.to('cpu'), \"Predictions\": test_pred.to('cpu').detach().numpy()})\n",
    "#, \"Date\": test_data['Date']})\n",
    "\n",
    "train_results.to_csv('../Results/train/BOW.csv', index=False)\n",
    "valid_results.to_csv('../Results/validation/BOW.csv', index=False)\n",
    "test_results.to_csv('../Results/test/BOW.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}